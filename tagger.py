# tagger.py

import torch
import timm
import onnxruntime
import numpy as np
import torchvision.transforms.functional as TVF
from PIL import Image
from pathlib import Path
from typing import List, Dict, Any, Optional # Optionalã‚’è¿½åŠ ï¼
import csv
import json
import logging

logger = logging.getLogger("uvicorn")

MODEL_PATH = Path('./models_data')
SAFETENSORS_MODEL_FILE = MODEL_PATH / 'model.safetensors'
ONNX_MODEL_FILE = MODEL_PATH / 'model.onnx'
CONFIG_FILE = MODEL_PATH / 'config.json'
TAG_FILE = MODEL_PATH / 'selected_tags.csv'

THRESHOLD = 0.35
DEVICE = 'cuda' if 'CUDAExecutionProvider' in onnxruntime.get_available_providers() else 'cpu'

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’ Optional ã«å¤‰æ›´ï¼ ---
ort_session: Optional[onnxruntime.InferenceSession] = None
tags_list: List[str] = []
translation_map: Dict[str, str] = {}
input_size: int = 448 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

def ensure_onnx_model_exists():
    if ONNX_MODEL_FILE.exists():
        logger.info(f"âœ… `{ONNX_MODEL_FILE}` ç™ºè¦‹ï¼å¤‰æ›ã¯ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã­ã€‚")
        return
    logger.warning(f"âš ï¸ `{ONNX_MODEL_FILE}` ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼ä»Šã‹ã‚‰safetensorsã‹ã‚‰å¤‰æ›ã™ã‚‹ã‚ˆã€‚ã¡ã‚‡ã£ã¨å¾…ã£ã¦ã¦ã­â€¦")
    if not SAFETENSORS_MODEL_FILE.exists():
        logger.error(f"âŒ ã†ãâ€¦è‚å¿ƒã® `{SAFETENSORS_MODEL_FILE}` ã‚‚ãªã„ã˜ã‚ƒã‚“ï¼ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã¦ï¼")
        raise FileNotFoundError(f"{SAFETENSORS_MODEL_FILE} not found.")
    try:
        with open(CONFIG_FILE, 'r') as f:
            config = json.load(f)
    except FileNotFoundError:
        logger.error(f"âŒ `{CONFIG_FILE}` ãŒãªã„ã‚ˆï¼ãƒ¢ãƒ‡ãƒ«ã¨ä¸€ç·’ã«é…å¸ƒã•ã‚Œã¦ã‚‹ã¯ãšã ã‹ã‚‰ç¢ºèªã—ã¦ï¼")
        raise
    logger.info("ãƒ¢ãƒ‡ãƒ«ã®éª¨æ ¼ã‚’timmã§ä½œæˆä¸­...")
    model = timm.create_model(
        'eva02_large_patch14_448.mim_in22k_ft_in22k_in1k',
        pretrained=False,
        num_classes=config['n_tags']
    )
    logger.info("safetensorsã‹ã‚‰é­‚ï¼ˆãŠã‚‚ã¿ï¼‰ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
    from safetensors.torch import load_file
    state_dict = load_file(SAFETENSORS_MODEL_FILE, device='cpu')
    model.load_state_dict(state_dict)
    model.eval()
    
    image_size = config.get('image_size', 448)
    dummy_input = torch.randn(1, 3, image_size, image_size, requires_grad=True)
    logger.info("âœ¨ ONNXã«å¤‰èº«é–‹å§‹ï¼ã“ã‚ŒãŒçµæ§‹æ™‚é–“ã‹ã‹ã‚‹ã‹ã‚‚â€¦ âœ¨")
    torch.onnx.export(
        model, dummy_input, str(ONNX_MODEL_FILE), export_params=True, opset_version=14,
        do_constant_folding=True, input_names=['input'], output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}}
    )
    logger.info(f"ðŸŽ‰ çˆ†é€ŸONNXãƒ¢ãƒ‡ãƒ« `{ONNX_MODEL_FILE}` ã®ä½œæˆå®Œäº†ï¼ ðŸŽ‰")

# --- â˜…â˜…â˜…ã“ã“ã‹ã‚‰ãŒæœ¬ç•ªï¼ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚’é–¢æ•°åŒ–â˜…â˜…â˜… ---
def load_model_and_tags():
    """
    ãƒ¢ãƒ‡ãƒ«ã¨ã‚¿ã‚°ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«è¨­å®šã™ã‚‹é–¢æ•°
    """
    global ort_session, tags_list, translation_map, input_size

    # 1. ONNXãƒ¢ãƒ‡ãƒ«ãŒãªã‹ã£ãŸã‚‰ä½œã‚‹
    ensure_onnx_model_exists()

    # 2. ONNXãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
    logger.info(f"Loading ONNX model from {ONNX_MODEL_FILE} on {DEVICE}...")
    providers = ['CUDAExecutionProvider'] if DEVICE == 'cuda' else ['CPUExecutionProvider']
    ort_session = onnxruntime.InferenceSession(str(ONNX_MODEL_FILE), providers=providers)
    input_size = ort_session.get_inputs()[0].shape[-1]
    logger.info("âœ… ONNXãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼")

    # 3. ã‚¿ã‚°ãƒªã‚¹ãƒˆã¨ç¿»è¨³è¾žæ›¸ã‚’ä½œæˆ
    if not TAG_FILE.exists():
        logger.error(f"âŒ {TAG_FILE} ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼å‡¦ç†ã‚’ä¸­æ–­ã™ã‚‹ã­ã€‚")
        raise FileNotFoundError(f"{TAG_FILE} ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‚ˆï¼")

    with open(TAG_FILE, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        header = next(reader)
        name_index = header.index('name')
        japanese_name_index = -1
        if 'japanese_name' in header:
            japanese_name_index = header.index('japanese_name')
        else:
             logger.warning("âš ï¸ 'japanese_name'åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‹ã‚‰ã€ç¿»è¨³æ©Ÿèƒ½ã¯ã‚ªãƒ•ã«ãªã‚‹ã‚ˆã€‚")
        
        # tags_listã¨translation_mapã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‹ã‚‰è¿½åŠ ã™ã‚‹
        tags_list.clear()
        translation_map.clear()

        for row in reader:
            try:
                english_tag = row[name_index].replace('_', ' ')
                tags_list.append(english_tag)
                if japanese_name_index != -1 and row[japanese_name_index]:
                    translation_map[english_tag] = row[japanese_name_index]
            except IndexError:
                continue
    logger.info("âœ… ã‚¿ã‚°ãƒªã‚¹ãƒˆã¨ç¿»è¨³è¾žæ›¸ã®èª­ã¿è¾¼ã¿å®Œäº†ï¼")


def prepare_image(image: Image.Image, target_size: int) -> np.ndarray:
    image_shape = image.size
    max_dim = max(image_shape)
    pad_left = (max_dim - image_shape[0]) // 2
    pad_top = (max_dim - image_shape[1]) // 2
    padded_image = Image.new('RGB', (max_dim, max_dim), (255, 255, 255))
    padded_image.paste(image, (pad_left, pad_top))
    if max_dim != target_size:
        padded_image = padded_image.resize((target_size, target_size), Image.BICUBIC)
    image_tensor = TVF.to_tensor(padded_image).unsqueeze(0)
    image_tensor = TVF.normalize(image_tensor, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    return image_tensor.numpy()

def predict(image: Image.Image) -> List[str]:
    if ort_session is None:
        raise RuntimeError("ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ãªã„ã£ã½ã„ï¼å…ˆã«load_model_and_tags()ã‚’å‘¼ã‚“ã§ã­ã€‚")
    
    image_np = prepare_image(image.convert("RGB"), input_size)
    input_name = ort_session.get_inputs()[0].name
    output_name = ort_session.get_outputs()[0].name
    ort_inputs = {input_name: image_np}
    ort_outs = ort_session.run([output_name], ort_inputs)[0]
    preds = 1 / (1 + np.exp(-ort_outs))
    tag_preds = preds[0]
    scores = {tags_list[i]: tag_preds[i] for i in range(len(tags_list))}
    predicted_tags = [tag for tag, score in scores.items() if score > THRESHOLD]
    translated_tags = [translation_map.get(tag, tag) for tag in predicted_tags]
    return translated_tags